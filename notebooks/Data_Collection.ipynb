{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86fa213-5c40-4668-8575-6f33313db139",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa194dc-e039-46af-b43b-a85fcc02f4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cbb3c-7c30-4059-9934-3c5b75010b4a",
   "metadata": {},
   "source": [
    "## Step 2: Define Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c13ff6-8570-4755-82a5-90f67fbff09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# NYC CitiBike Demand Analysis 2022\n",
       "\n",
       "## Project Overview\n",
       "- **Data Source**: Citi Bike System Data\n",
       "- **Analysis Period**: 2022\n",
       "- **Weather Station**: LaGuardia Airport (NYC)\n",
       "- **Station ID**: GHCND:USW00014732\n",
       "\n",
       "## Analysis Objectives\n",
       "1. Identify peak demand periods and popular stations\n",
       "2. Analyze seasonal patterns and weather impact\n",
       "3. Optimize bike distribution across NYC\n",
       "4. Identify expansion opportunities\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA Token: Loaded\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Use correct path for notebooks directory\n",
    "\n",
    "DATA_PATH = \"../data/raw/\"\n",
    "OUTPUT_PATH = \"../data/processed/\"\n",
    "NOAA_TOKEN = os.getenv('NOAA_TOKEN')\n",
    "\n",
    "# Display project information\n",
    "project_info = {\n",
    "    \"project_name\": \"NYC CitiBike Demand Analysis 2022\",\n",
    "    \"data_source\": \"Citi Bike System Data\",\n",
    "    \"year\": 2022,\n",
    "    \"weather_station\": \"LaGuardia Airport (NYC)\",\n",
    "    \"station_id\": \"GHCND:USW00014732\"\n",
    "}\n",
    "\n",
    "markdown_content = f\"\"\"\n",
    "# {project_info['project_name']}\n",
    "\n",
    "## Project Overview\n",
    "- **Data Source**: {project_info['data_source']}\n",
    "- **Analysis Period**: {project_info['year']}\n",
    "- **Weather Station**: {project_info['weather_station']}\n",
    "- **Station ID**: {project_info['station_id']}\n",
    "\n",
    "## Analysis Objectives\n",
    "1. Identify peak demand periods and popular stations\n",
    "2. Analyze seasonal patterns and weather impact\n",
    "3. Optimize bike distribution across NYC\n",
    "4. Identify expansion opportunities\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(markdown_content))\n",
    "print(f\"NOAA Token: {'Loaded' if NOAA_TOKEN else 'NOT FOUND - Check .env file'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e39d5-9da3-48ca-8dd2-3efe483b3f08",
   "metadata": {},
   "source": [
    "## Step 3: Load CtiBike Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b6aa27-65ff-4e52-9147-585cdd4ddd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CitiBike data files...\n",
      "Using data path: ../data/raw/\n",
      "Path exists: True\n",
      "Found 36 CSV files to process\n",
      "First 5 files:\n",
      "  1. 202201-citibike-tripdata_1.csv (185.56 MB)\n",
      "  2. 202201-citibike-tripdata_2.csv (4.5 MB)\n",
      "  3. 202202-citibike-tripdata_1.csv (185.96 MB)\n",
      "  4. 202202-citibike-tripdata_2.csv (36.84 MB)\n",
      "  5. 202203-citibike-tripdata_1.csv (186.27 MB)\n",
      "\n",
      "Starting to load files...\n",
      "Reading: 202201-citibike-tripdata_1.csv (185.6 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202201-citibike-tripdata_2.csv (4.5 MB)\n",
      "  Success: 24,555 rows, 14 columns\n",
      "Reading: 202202-citibike-tripdata_1.csv (186.0 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202202-citibike-tripdata_2.csv (36.8 MB)\n",
      "  Success: 197,312 rows, 14 columns\n",
      "Reading: 202203-citibike-tripdata_1.csv (186.3 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202203-citibike-tripdata_2.csv (157.5 MB)\n",
      "  Success: 845,965 rows, 14 columns\n",
      "Reading: 202204-citibike-tripdata_1.csv (186.4 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202204-citibike-tripdata_2.csv (186.5 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202204-citibike-tripdata_3.csv (48.7 MB)\n",
      "  Success: 260,790 rows, 14 columns\n",
      "Reading: 202205-citibike-tripdata_1.csv (186.8 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202205-citibike-tripdata_2.csv (186.8 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202205-citibike-tripdata_3.csv (161.0 MB)\n",
      "  Success: 865,425 rows, 14 columns\n",
      "Reading: 202206-citibike-tripdata_1.csv (186.8 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202206-citibike-tripdata_2.csv (186.7 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202206-citibike-tripdata_3.csv (186.8 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202206-citibike-tripdata_4.csv (64.4 MB)\n",
      "  Success: 343,914 rows, 14 columns\n",
      "Reading: 202207-citibike-tripdata_1.csv (186.6 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202207-citibike-tripdata_2.csv (186.5 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202207-citibike-tripdata_3.csv (187.6 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202207-citibike-tripdata_4.csv (74.2 MB)\n",
      "  Success: 397,932 rows, 14 columns\n",
      "Reading: 202208-citibike-tripdata_1.csv (187.7 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202208-citibike-tripdata_2.csv (187.0 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202208-citibike-tripdata_3.csv (185.8 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202208-citibike-tripdata_4.csv (107.9 MB)\n",
      "  Success: 576,020 rows, 14 columns\n",
      "Reading: 202209-citibike-tripdata_1.csv (186.4 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202209-citibike-tripdata_2.csv (186.8 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202209-citibike-tripdata_3.csv (187.4 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202209-citibike-tripdata_4.csv (76.8 MB)\n",
      "  Success: 411,866 rows, 14 columns\n",
      "Reading: 202210-citibike-tripdata_1.csv (186.3 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202210-citibike-tripdata_2.csv (187.2 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202210-citibike-tripdata_3.csv (175.5 MB)\n",
      "  Success: 936,584 rows, 14 columns\n",
      "Reading: 202211-citibike-tripdata_1.csv (186.8 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202211-citibike-tripdata_2.csv (186.6 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202211-citibike-tripdata_3.csv (72.2 MB)\n",
      "  Success: 386,394 rows, 14 columns\n",
      "Reading: 202212-citibike-tripdata_1.csv (186.4 MB)\n",
      "  Success: 1,000,000 rows, 14 columns\n",
      "Reading: 202212-citibike-tripdata_2.csv (111.0 MB)\n",
      "  Success: 592,049 rows, 14 columns\n",
      "\n",
      "=== SUCCESS ===\n",
      "Successfully concatenated 36 files\n",
      "Total dataset: 29,838,806 rows, 14 columns\n",
      "\n",
      "Date range:\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>_source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFD29218AB271154</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-21 13:13:43.392</td>\n",
       "      <td>2022-01-21 13:22:31.463</td>\n",
       "      <td>West End Ave &amp; W 107 St</td>\n",
       "      <td>7650.05</td>\n",
       "      <td>Mt Morris Park W &amp; W 120 St</td>\n",
       "      <td>7685.14</td>\n",
       "      <td>40.802117</td>\n",
       "      <td>-73.968181</td>\n",
       "      <td>40.804038</td>\n",
       "      <td>-73.945925</td>\n",
       "      <td>member</td>\n",
       "      <td>202201-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7C953F2FD7BE1302</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-10 11:30:54.162</td>\n",
       "      <td>2022-01-10 11:41:43.422</td>\n",
       "      <td>4 Ave &amp; 3 St</td>\n",
       "      <td>4028.04</td>\n",
       "      <td>Boerum Pl\\t&amp; Pacific St</td>\n",
       "      <td>4488.09</td>\n",
       "      <td>40.673746</td>\n",
       "      <td>-73.985649</td>\n",
       "      <td>40.688489</td>\n",
       "      <td>-73.991160</td>\n",
       "      <td>member</td>\n",
       "      <td>202201-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95893ABD40CED4B8</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-26 10:52:43.096</td>\n",
       "      <td>2022-01-26 11:06:35.227</td>\n",
       "      <td>1 Ave &amp; E 62 St</td>\n",
       "      <td>6753.08</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>6248.06</td>\n",
       "      <td>40.761227</td>\n",
       "      <td>-73.960940</td>\n",
       "      <td>40.745168</td>\n",
       "      <td>-73.986831</td>\n",
       "      <td>member</td>\n",
       "      <td>202201-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F853B50772137378</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-03 08:35:48.247</td>\n",
       "      <td>2022-01-03 09:10:50.475</td>\n",
       "      <td>2 Ave &amp; E 96 St</td>\n",
       "      <td>7338.02</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>6248.06</td>\n",
       "      <td>40.783964</td>\n",
       "      <td>-73.947167</td>\n",
       "      <td>40.745168</td>\n",
       "      <td>-73.986831</td>\n",
       "      <td>member</td>\n",
       "      <td>202201-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7590ADF834797B4B</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-22 14:14:23.043</td>\n",
       "      <td>2022-01-22 14:34:57.474</td>\n",
       "      <td>6 Ave &amp; W 34 St</td>\n",
       "      <td>6364.10</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>6248.06</td>\n",
       "      <td>40.749640</td>\n",
       "      <td>-73.988050</td>\n",
       "      <td>40.745168</td>\n",
       "      <td>-73.986831</td>\n",
       "      <td>member</td>\n",
       "      <td>202201-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type               started_at  \\\n",
       "0  BFD29218AB271154  electric_bike  2022-01-21 13:13:43.392   \n",
       "1  7C953F2FD7BE1302   classic_bike  2022-01-10 11:30:54.162   \n",
       "2  95893ABD40CED4B8  electric_bike  2022-01-26 10:52:43.096   \n",
       "3  F853B50772137378   classic_bike  2022-01-03 08:35:48.247   \n",
       "4  7590ADF834797B4B   classic_bike  2022-01-22 14:14:23.043   \n",
       "\n",
       "                  ended_at       start_station_name start_station_id  \\\n",
       "0  2022-01-21 13:22:31.463  West End Ave & W 107 St          7650.05   \n",
       "1  2022-01-10 11:41:43.422             4 Ave & 3 St          4028.04   \n",
       "2  2022-01-26 11:06:35.227          1 Ave & E 62 St          6753.08   \n",
       "3  2022-01-03 09:10:50.475          2 Ave & E 96 St          7338.02   \n",
       "4  2022-01-22 14:34:57.474          6 Ave & W 34 St          6364.10   \n",
       "\n",
       "              end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0  Mt Morris Park W & W 120 St        7685.14  40.802117 -73.968181   \n",
       "1      Boerum Pl\\t& Pacific St        4488.09  40.673746 -73.985649   \n",
       "2              5 Ave & E 29 St        6248.06  40.761227 -73.960940   \n",
       "3              5 Ave & E 29 St        6248.06  40.783964 -73.947167   \n",
       "4              5 Ave & E 29 St        6248.06  40.749640 -73.988050   \n",
       "\n",
       "     end_lat    end_lng member_casual                    _source_file  \n",
       "0  40.804038 -73.945925        member  202201-citibike-tripdata_1.csv  \n",
       "1  40.688489 -73.991160        member  202201-citibike-tripdata_1.csv  \n",
       "2  40.745168 -73.986831        member  202201-citibike-tripdata_1.csv  \n",
       "3  40.745168 -73.986831        member  202201-citibike-tripdata_1.csv  \n",
       "4  40.745168 -73.986831        member  202201-citibike-tripdata_1.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CitiBike Data\n",
    "\n",
    "print(\"Loading CitiBike data files...\")\n",
    "\n",
    "print(f\"Using data path: {DATA_PATH}\")\n",
    "print(f\"Path exists: {os.path.exists(DATA_PATH)}\")\n",
    "\n",
    "# Get all CSV files\n",
    "all_files = []\n",
    "for item in os.listdir(DATA_PATH):\n",
    "    if item.endswith('.csv') and '2022' in item and 'citibike' in item:\n",
    "        full_path = os.path.join(DATA_PATH, item)\n",
    "        all_files.append(full_path)\n",
    "\n",
    "all_files = sorted(all_files)\n",
    "file_count = len(all_files)\n",
    "\n",
    "print(f\"Found {file_count} CSV files to process\")\n",
    "\n",
    "# Display first few files\n",
    "print(\"First 5 files:\")\n",
    "for i, file_path in enumerate(all_files[:5], 1):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_size = round(os.path.getsize(file_path) / (1024*1024), 2)\n",
    "    print(f\"  {i}. {file_name} ({file_size} MB)\")\n",
    "\n",
    "def read_citibike_file(file_path):\n",
    "    try:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
    "        print(f\"Reading: {file_name} ({file_size:.1f} MB)\")\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        df['_source_file'] = file_name\n",
    "        print(f\"  Success: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\nStarting to load files...\")\n",
    "dataframes = []\n",
    "for file_path in all_files:\n",
    "    df = read_citibike_file(file_path)\n",
    "    if df is not None:\n",
    "        dataframes.append(df)\n",
    "\n",
    "if dataframes:\n",
    "    df_bikes = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"\\n=== SUCCESS ===\")\n",
    "    print(f\"Successfully concatenated {len(dataframes)} files\")\n",
    "    print(f\"Total dataset: {len(df_bikes):,} rows, {len(df_bikes.columns)} columns\")\n",
    "    \n",
    "    # Display dataset info\n",
    "    print(f\"\\nDate range:\")\n",
    "    # Find datetime columns\n",
    "    datetime_cols = [col for col in df_bikes.columns if 'time' in col.lower() or 'date' in col.lower()]\n",
    "    if datetime_cols:\n",
    "        for col in datetime_cols[:2]:  # Check first 2 datetime columns\n",
    "            if col in df_bikes.columns:\n",
    "                print(f\"  {col}: {df_bikes[col].min()} to {df_bikes[col].max()}\")\n",
    "    \n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    display(df_bikes.head(5))\n",
    "    \n",
    "else:\n",
    "    raise Exception(\"No data files were successfully loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd4a16-17a6-430f-91db-9c33503cb205",
   "metadata": {},
   "source": [
    "## Step 4: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0347dcf-3488-47bd-97c2-09c5c1acc750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data cleaning and preprocessing...\n",
      "Converting datetime columns...\n",
      "Data cleaning complete:\n",
      "  - Initial rows: 29,838,806\n",
      "  - Rows removed (invalid dates): 0\n",
      "  - Final rows: 29,838,806\n",
      "  - Data retention: 100.0%\n",
      "\n",
      "Date range:\n",
      "  - Earliest trip: 2021-01-30 17:30:45.544000\n",
      "  - Latest trip: 2022-12-31 23:58:19.206000\n",
      "  - Total days: 402\n",
      "\n",
      "Basic statistics:\n",
      "  - Member vs Casual:\n",
      "    {'member': 23257785, 'casual': 6581021}\n",
      "  - Bike types:\n",
      "    {'classic_bike': 18105492, 'electric_bike': 11733314}\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning & Preprocessing\n",
    "\n",
    "print(\"Starting data cleaning and preprocessing...\")\n",
    "\n",
    "# Convert datetime columns\n",
    "print(\"Converting datetime columns...\")\n",
    "df_bikes['started_at'] = pd.to_datetime(df_bikes['started_at'], errors='coerce')\n",
    "df_bikes['ended_at'] = pd.to_datetime(df_bikes['ended_at'], errors='coerce')\n",
    "\n",
    "# Extract date for weather merging\n",
    "df_bikes['date'] = df_bikes['started_at'].dt.date\n",
    "df_bikes['date'] = pd.to_datetime(df_bikes['date'])\n",
    "\n",
    "# Data quality check\n",
    "initial_rows = len(df_bikes)\n",
    "df_bikes = df_bikes.dropna(subset=['started_at', 'ended_at'])\n",
    "final_rows = len(df_bikes)\n",
    "removed_rows = initial_rows - final_rows\n",
    "\n",
    "print(f\"Data cleaning complete:\")\n",
    "print(f\"  - Initial rows: {initial_rows:,}\")\n",
    "print(f\"  - Rows removed (invalid dates): {removed_rows:,}\")\n",
    "print(f\"  - Final rows: {final_rows:,}\")\n",
    "print(f\"  - Data retention: {round((final_rows/initial_rows)*100, 2)}%\")\n",
    "\n",
    "# Display date range\n",
    "print(f\"\\nDate range:\")\n",
    "print(f\"  - Earliest trip: {df_bikes['started_at'].min()}\")\n",
    "print(f\"  - Latest trip: {df_bikes['started_at'].max()}\")\n",
    "print(f\"  - Total days: {df_bikes['date'].nunique()}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(f\"  - Member vs Casual:\")\n",
    "print(f\"    {df_bikes['member_casual'].value_counts().to_dict()}\")\n",
    "print(f\"  - Bike types:\")\n",
    "print(f\"    {df_bikes['rideable_type'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef37bfb3-9402-443a-b3f2-c934a5d41b20",
   "metadata": {},
   "source": [
    "## Step 5: Fetch Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c3cf46-ee06-49e0-9036-633f1cb13146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather data from NOAA API...\n",
      "Successfully retrieved 365 days of weather data\n",
      "\n",
      "Weather data summary:\n",
      "  - Date range: 2022-01-01 to 2022-12-31\n",
      "  - Average temperature: 13.8°C (56.8°F)\n",
      "  - Min temperature: -11.7°C\n",
      "  - Max temperature: 31.3°C\n",
      "\n",
      "Sample of weather data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_temp_c</th>\n",
       "      <th>avg_temp_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>11.6</td>\n",
       "      <td>52.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>11.4</td>\n",
       "      <td>52.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>1.4</td>\n",
       "      <td>34.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>27.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>3.2</td>\n",
       "      <td>37.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  avg_temp_c  avg_temp_f\n",
       "0 2022-01-01        11.6       52.88\n",
       "1 2022-01-02        11.4       52.52\n",
       "2 2022-01-03         1.4       34.52\n",
       "3 2022-01-04        -2.7       27.14\n",
       "4 2022-01-05         3.2       37.76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch Weather Data from NOAA API\n",
    "\n",
    "print(\"Fetching weather data from NOAA API...\")\n",
    "\n",
    "station_id = \"GHCND:USW00014732\"  # LaGuardia Airport, NYC\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "noaa_url = (\n",
    "    f\"https://www.ncdc.noaa.gov/cdo-web/api/v2/data?\"\n",
    "    f\"datasetid=GHCND&datatypeid=TAVG&limit=1000&\"\n",
    "    f\"stationid={station_id}&startdate={start_date}&enddate={end_date}\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    headers = {'token': NOAA_TOKEN}\n",
    "    response = requests.get(noaa_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        weather_data = json.loads(response.text)\n",
    "        \n",
    "        if 'results' in weather_data and weather_data['results']:\n",
    "            # Extract temperature data\n",
    "            avg_temps = [item for item in weather_data['results'] if item['datatype'] == 'TAVG']\n",
    "            dates_temp = [item['date'] for item in avg_temps]\n",
    "            temps = [item['value'] for item in avg_temps]\n",
    "            \n",
    "            # Create weather dataframe\n",
    "            df_weather = pd.DataFrame()\n",
    "            df_weather['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "            df_weather['avg_temp_c'] = [float(v) / 10.0 for v in temps]  # Convert to Celsius\n",
    "            df_weather['avg_temp_f'] = df_weather['avg_temp_c'] * 9/5 + 32  # Convert to Fahrenheit\n",
    "            \n",
    "            print(f\"Successfully retrieved {len(df_weather)} days of weather data\")\n",
    "            \n",
    "            # Display weather summary\n",
    "            print(f\"\\nWeather data summary:\")\n",
    "            print(f\"  - Date range: {df_weather['date'].min().strftime('%Y-%m-%d')} to {df_weather['date'].max().strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  - Average temperature: {df_weather['avg_temp_c'].mean():.1f}°C ({df_weather['avg_temp_f'].mean():.1f}°F)\")\n",
    "            print(f\"  - Min temperature: {df_weather['avg_temp_c'].min():.1f}°C\")\n",
    "            print(f\"  - Max temperature: {df_weather['avg_temp_c'].max():.1f}°C\")\n",
    "            \n",
    "        else:\n",
    "            print(\"No weather data returned from API\")\n",
    "            df_weather = pd.DataFrame(columns=['date', 'avg_temp_c', 'avg_temp_f'])\n",
    "            \n",
    "    else:\n",
    "        print(f\"API request failed with status code: {response.status_code}\")\n",
    "        df_weather = pd.DataFrame(columns=['date', 'avg_temp_c', 'avg_temp_f'])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching weather data: {e}\")\n",
    "    df_weather = pd.DataFrame(columns=['date', 'avg_temp_c', 'avg_temp_f'])\n",
    "\n",
    "# Display sample of weather data\n",
    "if not df_weather.empty:\n",
    "    print(f\"\\nSample of weather data:\")\n",
    "    display(df_weather.head())\n",
    "else:\n",
    "    print(\"No weather data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344d06a-b72c-4f1f-9287-6bfadf4350b0",
   "metadata": {},
   "source": [
    "## Step 6: Merge Datastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b06715e7-e1b8-44ec-ab9f-478c892613bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging bike data with weather data...\n",
      "Merge completed:\n",
      "  - Both (successful matches): 29,838,166 rows\n",
      "  - Left only (no weather data): 640 rows\n",
      "  - Right only (extra weather data): 0 rows\n",
      "  - Merge success rate: 100.0%\n",
      "\n",
      "Final merged dataset:\n",
      "  - Total rows: 29,838,806\n",
      "  - Total columns: 17\n",
      "  - Memory usage: 16.16 GB\n",
      "\n",
      "Final dataset columns:\n",
      "  - ride_id\n",
      "  - rideable_type\n",
      "  - started_at\n",
      "  - ended_at\n",
      "  - start_station_name\n",
      "  - start_station_id\n",
      "  - end_station_name\n",
      "  - end_station_id\n",
      "  - start_lat\n",
      "  - start_lng\n",
      "  - end_lat\n",
      "  - end_lng\n",
      "  - member_casual\n",
      "  - _source_file\n",
      "  - date\n",
      "  - avg_temp_c\n",
      "  - avg_temp_f\n"
     ]
    }
   ],
   "source": [
    "# Merge Bike Data with Weather Data\n",
    "\n",
    "print(\"Merging bike data with weather data...\")\n",
    "\n",
    "if not df_weather.empty:\n",
    "    df_merged = df_bikes.merge(df_weather, how='left', on='date', indicator=True)\n",
    "    \n",
    "    # Analyze merge results\n",
    "    merge_stats = df_merged['_merge'].value_counts()\n",
    "    \n",
    "    print(f\"Merge completed:\")\n",
    "    print(f\"  - Both (successful matches): {merge_stats.get('both', 0):,} rows\")\n",
    "    print(f\"  - Left only (no weather data): {merge_stats.get('left_only', 0):,} rows\")\n",
    "    print(f\"  - Right only (extra weather data): {merge_stats.get('right_only', 0):,} rows\")\n",
    "    print(f\"  - Merge success rate: {round((merge_stats.get('both', 0) / len(df_merged)) * 100, 2)}%\")\n",
    "    \n",
    "    # Remove merge indicator column\n",
    "    df_merged = df_merged.drop('_merge', axis=1)\n",
    "    \n",
    "else:\n",
    "    df_merged = df_bikes.copy()\n",
    "    df_merged['avg_temp_c'] = np.nan\n",
    "    df_merged['avg_temp_f'] = np.nan\n",
    "    print(\"No weather data available - proceeding with NaN values for temperature\")\n",
    "\n",
    "print(f\"\\nFinal merged dataset:\")\n",
    "print(f\"  - Total rows: {len(df_merged):,}\")\n",
    "print(f\"  - Total columns: {len(df_merged.columns)}\")\n",
    "print(f\"  - Memory usage: {round(df_merged.memory_usage(deep=True).sum() / (1024**3), 2)} GB\")\n",
    "\n",
    "# Display final dataset structure\n",
    "print(f\"\\nFinal dataset columns:\")\n",
    "for col in df_merged.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c495ef-3f90-4012-8738-7b08af0afff9",
   "metadata": {},
   "source": [
    "## Step 7: Export Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9147b460-8fb4-44a1-9672-ffe80749cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting processed data...\n",
      "Output file: ../data/processed/nyc_citibike_2022_processed.csv\n",
      "Export completed successfully:\n",
      "  - File size: 6.96 GB\n",
      "  - Total rows: 29,838,806\n",
      "  - Total columns: 17\n",
      "  - Export timestamp: 2025-10-31 09:26:54\n",
      "\n",
      "Sample of exported data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>avg_temp_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-21 13:13:43.392</td>\n",
       "      <td>2022-01-21 13:22:31.463</td>\n",
       "      <td>West End Ave &amp; W 107 St</td>\n",
       "      <td>Mt Morris Park W &amp; W 120 St</td>\n",
       "      <td>member</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-10 11:30:54.162</td>\n",
       "      <td>2022-01-10 11:41:43.422</td>\n",
       "      <td>4 Ave &amp; 3 St</td>\n",
       "      <td>Boerum Pl\\t&amp; Pacific St</td>\n",
       "      <td>member</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-26 10:52:43.096</td>\n",
       "      <td>2022-01-26 11:06:35.227</td>\n",
       "      <td>1 Ave &amp; E 62 St</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>member</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-03 08:35:48.247</td>\n",
       "      <td>2022-01-03 09:10:50.475</td>\n",
       "      <td>2 Ave &amp; E 96 St</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>member</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-22 14:14:23.043</td>\n",
       "      <td>2022-01-22 14:34:57.474</td>\n",
       "      <td>6 Ave &amp; W 34 St</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>member</td>\n",
       "      <td>-5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               started_at                ended_at       start_station_name  \\\n",
       "0 2022-01-21 13:13:43.392 2022-01-21 13:22:31.463  West End Ave & W 107 St   \n",
       "1 2022-01-10 11:30:54.162 2022-01-10 11:41:43.422             4 Ave & 3 St   \n",
       "2 2022-01-26 10:52:43.096 2022-01-26 11:06:35.227          1 Ave & E 62 St   \n",
       "3 2022-01-03 08:35:48.247 2022-01-03 09:10:50.475          2 Ave & E 96 St   \n",
       "4 2022-01-22 14:14:23.043 2022-01-22 14:34:57.474          6 Ave & W 34 St   \n",
       "\n",
       "              end_station_name member_casual  avg_temp_c  \n",
       "0  Mt Morris Park W & W 120 St        member        -6.0  \n",
       "1      Boerum Pl\\t& Pacific St        member         1.6  \n",
       "2              5 Ave & E 29 St        member        -2.3  \n",
       "3              5 Ave & E 29 St        member         1.4  \n",
       "4              5 Ave & E 29 St        member        -5.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export Processed Data\n",
    "\n",
    "print(\"Exporting processed data...\")\n",
    "\n",
    "output_file = os.path.join(OUTPUT_PATH, \"nyc_citibike_2022_processed.csv\")\n",
    "print(f\"Output file: {output_file}\")\n",
    "\n",
    "# Save to CSV\n",
    "df_merged.to_csv(output_file, index=False)\n",
    "\n",
    "# Verify file was created\n",
    "if os.path.exists(output_file):\n",
    "    file_size = round(os.path.getsize(output_file) / (1024**3), 2)\n",
    "    print(f\"Export completed successfully:\")\n",
    "    print(f\"  - File size: {file_size} GB\")\n",
    "    print(f\"  - Total rows: {len(df_merged):,}\")\n",
    "    print(f\"  - Total columns: {len(df_merged.columns)}\")\n",
    "    print(f\"  - Export timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Display sample of exported data\n",
    "    print(f\"\\nSample of exported data:\")\n",
    "    sample_cols = ['started_at', 'ended_at', 'start_station_name', 'end_station_name', 'member_casual', 'avg_temp_c']\n",
    "    available_cols = [col for col in sample_cols if col in df_merged.columns]\n",
    "    display(df_merged[available_cols].head(5))\n",
    "    \n",
    "else:\n",
    "    print(\"Error: Output file was not created successfully\")\n",
    "    raise Exception(\"Data export failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f63608-09d2-4490-a2d8-6343b2544126",
   "metadata": {},
   "source": [
    "## Step 8: Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "934701ea-4252-494d-8e43-a765cc848483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating project summary...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Data Collection Phase Complete\n",
       "\n",
       "## Project Summary\n",
       "\n",
       "### Data Processing Results\n",
       "- **Total Bike Trips Processed**: 29,838,806\n",
       "- **Data Files Consolidated**: 36\n",
       "- **Days in Dataset**: 402\n",
       "- **Weather Data Points**: 365\n",
       "- **Final Dataset Size**: 16.16 GB\n",
       "\n",
       "### User Statistics\n",
       "- **Member Rides**: 23,257,785\n",
       "- **Casual Rides**: 6,581,021\n",
       "\n",
       "### Bike Type Distribution\n",
       "- **classic_bike**: 18,105,492\n",
       "- **electric_bike**: 11,733,314\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Project Summary\n",
    "print(\"Generating project summary...\")\n",
    "\n",
    "summary_stats = {\n",
    "    'total_trips': len(df_merged),\n",
    "    'date_range_days': df_merged['date'].nunique(),\n",
    "    'data_files_processed': len(dataframes),\n",
    "    'weather_days_integrated': len(df_weather) if not df_weather.empty else 0,\n",
    "    'memory_usage_gb': round(df_merged.memory_usage(deep=True).sum() / (1024**3), 2),\n",
    "    'completion_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "# Calculate additional statistics\n",
    "user_types = df_merged['member_casual'].value_counts()\n",
    "bike_types = df_merged['rideable_type'].value_counts()\n",
    "\n",
    "markdown_content = f\"\"\"\n",
    "# Data Collection Phase Complete\n",
    "\n",
    "## Project Summary\n",
    "\n",
    "### Data Processing Results\n",
    "- **Total Bike Trips Processed**: {summary_stats['total_trips']:,}\n",
    "- **Data Files Consolidated**: {summary_stats['data_files_processed']}\n",
    "- **Days in Dataset**: {summary_stats['date_range_days']}\n",
    "- **Weather Data Points**: {summary_stats['weather_days_integrated']}\n",
    "- **Final Dataset Size**: {summary_stats['memory_usage_gb']} GB\n",
    "\n",
    "### User Statistics\n",
    "- **Member Rides**: {user_types.get('member', 0):,}\n",
    "- **Casual Rides**: {user_types.get('casual', 0):,}\n",
    "\n",
    "### Bike Type Distribution\n",
    "\"\"\"\n",
    "\n",
    "for bike_type, count in bike_types.items():\n",
    "    markdown_content += f\"- **{bike_type}**: {count:,}\\n\"\n",
    "\n",
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503a053-506f-4e80-9a6c-470f1ae51be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
